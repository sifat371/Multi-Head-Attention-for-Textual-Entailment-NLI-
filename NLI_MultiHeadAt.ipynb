{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dac727c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:29:10) [GCC 14.3.0]\n",
      "Torch: 2.9.0+cu128 CUDA: True\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — environment check and imports\n",
    "# Run this to ensure required libs are available and to import everything we'll use.\n",
    "import sys, math, os\n",
    "import torch\n",
    "print(\"Python:\", sys.version.splitlines()[0])\n",
    "print(\"Torch:\", getattr(torch, \"__version__\", \"n/a\"), \"CUDA:\", torch.cuda.is_available())\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a309874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: dict_keys(['test', 'validation', 'train'])\n",
      "Sizes: train 550152 validation 10000 test 10000\n",
      "\n",
      "Example 0:\n",
      " Premise: A person on a horse jumps over a broken down airplane.\n",
      " Hypothesis: A person is training his horse for a competition.\n",
      " Label: 1  (0=entailment, 1=neutral, 2=contradiction; -1 may mean missing)\n",
      "\n",
      "Example 1:\n",
      " Premise: A person on a horse jumps over a broken down airplane.\n",
      " Hypothesis: A person is at a diner, ordering an omelette.\n",
      " Label: 2  (0=entailment, 1=neutral, 2=contradiction; -1 may mean missing)\n",
      "\n",
      "Example 2:\n",
      " Premise: A person on a horse jumps over a broken down airplane.\n",
      " Hypothesis: A person is outdoors, on a horse.\n",
      " Label: 0  (0=entailment, 1=neutral, 2=contradiction; -1 may mean missing)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — load SNLI and inspect raw examples\n",
    "snli = load_dataset(\"snli\")\n",
    "print(\"Splits:\", snli.keys())\n",
    "print(\"Sizes: train\", len(snli[\"train\"]), \"validation\", len(snli[\"validation\"]), \"test\", len(snli[\"test\"]))\n",
    "\n",
    "# show first 3 raw examples (these are plain python dicts)\n",
    "for i in range(3):\n",
    "    ex = snli[\"train\"][i]\n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(\" Premise:\", ex[\"premise\"])\n",
    "    print(\" Hypothesis:\", ex[\"hypothesis\"])\n",
    "    print(\" Label:\", ex[\"label\"], \" (0=entailment, 1=neutral, 2=contradiction; -1 may mean missing)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7bc0a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts (train): Counter({0: 183416, 2: 183187, 1: 182764})\n",
      "Label counts (validation): Counter({0: 3329, 2: 3278, 1: 3235})\n",
      "Label counts (test): Counter({0: 3368, 2: 3237, 1: 3219})\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — filter invalid labels and look at label distribution\n",
    "snli = snli.filter(lambda ex: ex[\"label\"] is not None and ex[\"label\"] >= 0)\n",
    "from collections import Counter\n",
    "def label_counts(split):\n",
    "    return Counter([ex[\"label\"] for ex in snli[split]])\n",
    "print(\"Label counts (train):\", label_counts(\"train\"))\n",
    "print(\"Label counts (validation):\", label_counts(\"validation\"))\n",
    "print(\"Label counts (test):\", label_counts(\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "668d3dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer: BertTokenizerFast\n",
      "Vocab size: 30522\n",
      "Pad token id: 0 Pad token: [PAD]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c79cd7d00494ae092c043433ca49378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2652dfc2b5341cfaf4e92fc59acb13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9842 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd77f0935d24672a7f4c23496f488df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/549367 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['premise_input_ids', 'premise_attention_mask', 'hypo_input_ids', 'hypo_attention_mask'],\n",
      "        num_rows: 9824\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['premise_input_ids', 'premise_attention_mask', 'hypo_input_ids', 'hypo_attention_mask'],\n",
      "        num_rows: 9842\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['premise_input_ids', 'premise_attention_mask', 'hypo_input_ids', 'hypo_attention_mask'],\n",
      "        num_rows: 549367\n",
      "    })\n",
      "})\n",
      "Columns: ['premise_input_ids', 'premise_attention_mask', 'hypo_input_ids', 'hypo_attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — tokenizer: what it *does* and when it runs\n",
    "# We'll use a transformers tokenizer (subword/BERT-style). It converts text -> token ids and creates attention mask.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", use_fast=True)\n",
    "print(\"Tokenizer:\", tokenizer.__class__.__name__)\n",
    "print(\"Vocab size:\", tokenizer.vocab_size)\n",
    "print(\"Pad token id:\", tokenizer.pad_token_id, \"Pad token:\", tokenizer.pad_token)\n",
    "\n",
    "# 2️⃣  Decide maximum length\n",
    "#    SNLI sentences are short, 64 tokens is plenty\n",
    "max_len = 64\n",
    "\n",
    "# 3️⃣  Define a function that tokenizes both premise & hypothesis separately\n",
    "def tokenize_pair(batch):\n",
    "    premise = tokenizer(batch[\"premise\"], truncation=True, padding=\"max_length\", max_length=max_len)\n",
    "    hypo    = tokenizer(batch[\"hypothesis\"], truncation=True, padding=\"max_length\", max_length=max_len)\n",
    "    return {\n",
    "        \"premise_input_ids\": premise[\"input_ids\"],\n",
    "        \"premise_attention_mask\": premise[\"attention_mask\"],\n",
    "        \"hypo_input_ids\": hypo[\"input_ids\"],\n",
    "        \"hypo_attention_mask\": hypo[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "# 4️⃣  Apply this function to *every example* in all splits\n",
    "#    remove_columns removes the old text columns to save space\n",
    "snli_tok = snli.map(tokenize_pair, batched=True, remove_columns=snli[\"train\"].column_names)\n",
    "\n",
    "print(snli_tok)\n",
    "print(\"Columns:\", snli_tok[\"train\"].column_names)\n",
    "\n",
    "# NOTE: tokenizers map text -> ids (and produce masks). This step is CPU work (fast with 'use_fast').\n",
    "# You can run this once for the whole dataset (pre-tokenize) or run it each batch (on-the-fly).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
